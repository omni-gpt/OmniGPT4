data:
  class_path: omnigpt4.data.pl_modules.ImageTextPair
  init_args:
    datasets:
      - urls:
          - data/cc_sbu_align/wds.tar
    batch_size: 6
    num_workers: 8
    tokenizer_name_or_path: ./weights/vicuna-7b-v0
    max_tokens: 256
    end_sym: "###"
    prompt_template: "###Human: {} ###Assistant: "
    prompts_path: data/minigpt4_align_prompts.txt

model:
  class_path: omnigpt4.pl_modules.omnigpt4.OmniGPT4
  init_args:
    visual_model_name_or_path: Salesforce/blip2-flan-t5-xxl
    language_projection_weight_path: ./weights/language_projection_weights_checkpoints_00020000.safetensors
    language_model_name_or_path: ./weights/vicuna-7b-v0
    attention_type: torch_sdpa
    optimizer_config:
      init_lr: 3e-5
      min_lr: 1e-5
      betas: [0.9, 0.999]
      weight_decay: 0.05
      norm_weight_decay: 0.0
      num_warmup_steps: 200
      warmup_init_lr: 1e-6

trainer:
  devices: 2
  strategy: deepspeed_stage_2
  max_steps: 2_000
  precision: 16-mixed

  logger:
    - class_path: omnigpt4.utils.logger.WandbLogger
      init_args:
        project: OmniGPT4
        entity: sotalab
        name: minigpt4_stage_2

  callbacks:
    - class_path: TQDMProgressBar
      init_args:
        refresh_rate: 50
    - class_path: ModelCheckpoint
      init_args:
        filename: "ckpt_{step:08d}"
        auto_insert_metric_name: False
        save_top_k: -1
        every_n_train_steps: 1_000
    - LearningRateMonitor

  default_root_dir: wandb
  num_sanity_val_steps: 0

seed_everything: 2333
